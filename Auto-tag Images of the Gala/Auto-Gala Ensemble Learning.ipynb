{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport cv2\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.keras.applications import ResNet50, DenseNet121, VGG16, InceptionResNetV2\nfrom tensorflow.keras.layers import Flatten,Dense,Dropout,BatchNormalization\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/classification-of-images/dataset/train.csv')\ntest = pd.read_csv('/kaggle/input/classification-of-images/dataset/test.csv')\ntrain.head()","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"            Image   Class\n0   image7042.jpg    Food\n1   image3327.jpg    misc\n2  image10335.jpg  Attire\n3   image8019.jpg    Food\n4   image2128.jpg  Attire","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>image7042.jpg</td>\n      <td>Food</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>image3327.jpg</td>\n      <td>misc</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>image10335.jpg</td>\n      <td>Attire</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>image8019.jpg</td>\n      <td>Food</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>image2128.jpg</td>\n      <td>Attire</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Class_map = {'Food': 0, 'Attire': 1, 'Decorationandsignage': 2, 'misc': 3}\ninverse_map = {0: 'Food', 1: 'Attire', 2: 'Decorationandsignage', 3: 'misc'}\ntrain['Class'] = train['Class'].map(Class_map)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_img = []\ntrain_label = []\nj = 0\npath = '/kaggle/input/classification-of-images/dataset/Train Images'\nfor i in tqdm(train['Image']):\n    final_path = os.path.join(path, i)\n    img = cv2.imread(final_path)\n    img = cv2.resize(img, (150, 150))\n    img = img.astype('float32')\n    train_img.append(img)\n    train_label.append(train['Class'][j])\n    j=j+1","execution_count":null,"outputs":[{"output_type":"stream","text":" 98%|█████████▊| 5841/5983 [00:14<00:00, 405.68it/s]","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ndatagen.fit(train_img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_img = []\npath = '/kaggle/input/classification-of-images/dataset/Test Images'\nfor i in tqdm(test['Image']):\n    final_path = os.path.join(path,i)\n    img = cv2.imread(final_path)\n    img = cv2.resize(img,(150,150))\n    img = img.astype('float32')\n    test_img.append(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_img = np.array(train_img)\ntest_img = np.array(test_img)\ntrain_label = np.array(train_label)\nprint(train_img.shape)\nprint(test_img.shape)\nprint(train_label.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_models = [VGG16(include_top=False, weights='imagenet',input_shape=(150,150,3), pooling='avg'),\n              ResNet50(include_top=False, weights='imagenet',input_shape=(150,150,3), pooling='avg'),\n              DenseNet121(include_top=False, weights='imagenet',input_shape=(150,150,3), pooling='avg'),\n              InceptionResNetV2(include_top=False, weights='imagenet',input_shape=(150,150,3), pooling='avg')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(base_model, random_hidden_units):    \n    base_model.trainable = False\n    model = Sequential()\n    model.add(base_model)\n    model.add(Dense(random_hidden_units,activation='relu'))\n    model.add(Dense(4,activation='softmax'))\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_train, x, y, z = train_img.shape\nn_test, x, y, z = test_img.shape\nnumFeatures = x * y * z","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels = to_categorical(train_label,4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(seed=1997)\n# Number of estimators\nn_estimators = 4\n# Proporition of samples to use to train each training\nmax_samples = 0.7\nmax_samples *= n_train\nmax_samples = int(max_samples)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = list()\n# random = np.random.randint(50, 256, size=n_estimators)\nrandom = [256]*4\n\nfor i in range(n_estimators):    \n    # Model\n    model = create_model(base_models[i], random[i])    \n    \n    reduce_learning_rate = ReduceLROnPlateau(monitor='loss',\n                                         factor=0.1,\n                                         patience=2,\n                                         cooldown=2,\n                                         min_lr=0.00001,\n                                         verbose=1)\n\n    callbacks = [reduce_learning_rate]\n\n    model.compile(optimizer='adam',\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])    \n    \n    # Store model\n    models.append(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"histories = []\n\nfor i in range(n_estimators):\n    # Train each model on a bag of the training data\n    train_idx = np.random.choice(len(train_img),\n                                 size = max_samples)\n    \n    histories.append(models[i].fit_generator(datagen.flow(train_img[train_idx], \n                                                          train_labels[train_idx], \n                                                          batch_size=32),\n                                             epochs=10,\n                                             callbacks=callbacks))    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"predictions = []\nfor i in range(n_estimators):\n    predictions.append(models[i].predict(test_img))\n    \npredictions = np.array(predictions)\npredictions = predictions.sum(axis = 0)\npred_labels = predictions.argmax(axis=1)\n\nclass_label = [inverse_map[x] for x in pred_labels]\nprint(class_label[:3])\nsubmission = pd.DataFrame({'Image': test.Image, 'Class': class_label })\nsubmission.head(10)\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}